# ScriptGuard Training Parameters Guide

**Wersja:** 1.0
**Ostatnia aktualizacja:** 2026-02-10
**Model:** bigcode/starcoder2-3b + QLoRA

---

## ğŸ“‹ Spis treÅ›ci

1. [Model & Hardware](#1-model--hardware)
2. [Batching & Memory](#2-batching--memory)
3. [QLoRA Configuration](#3-qlora-configuration)
4. [Optimization & Regularization](#4-optimization--regularization)
5. [Learning Rate Scheduling](#5-learning-rate-scheduling)
6. [Evaluation & Monitoring](#6-evaluation--monitoring)
7. [Early Stopping](#7-early-stopping)
8. [Precision & Performance](#8-precision--performance)
9. [Experiment Tracking](#9-experiment-tracking)

---

## 1. Model & Hardware

### `model_id`
**Typ:** `string`
**DomyÅ›lnie:** `"bigcode/starcoder2-3b"`

**Opis:**
Identyfikator modelu bazowego z Hugging Face Hub. StarCoder2-3B to model specjalizowany w kodzie, zoptymalizowany pod QLoRA fine-tuning.

**WpÅ‚yw:**
- WiÄ™kszy model (7B, 15B) â†’ lepsza accuracy, ale wymaga wiÄ™cej VRAM
- Mniejszy model (1B) â†’ szybszy training, mniejsza accuracy

**Sugerowane wartoÅ›ci:**

| GPU VRAM | Model | Use Case |
|----------|-------|----------|
| 8-12 GB | `bigcode/starcoder2-1b` | Prototyping, szybki development |
| 16-24 GB | `bigcode/starcoder2-3b` | **Produkcja (24GB optimal)** |
| 40-80 GB | `bigcode/starcoder2-7b` | Maximum accuracy, research |

**Aktualna wartoÅ›Ä‡:** `bigcode/starcoder2-3b` âœ…

---

### `device`
**Typ:** `string`
**DomyÅ›lnie:** `"cuda"`

**Opis:**
UrzÄ…dzenie do trenowania modelu.

**WpÅ‚yw:**
- `cuda` â†’ GPU training (100x szybsze)
- `cpu` â†’ Bardzo wolne (tylko do testÃ³w)

**Sugerowane wartoÅ›ci:**
- **Zawsze `cuda`** jeÅ›li masz GPU
- `cpu` tylko do debugowania (bez treningu)

**Aktualna wartoÅ›Ä‡:** `cuda` âœ…

---

### `gradient_checkpointing`
**Typ:** `boolean`
**DomyÅ›lnie:** `true`

**Opis:**
Zapisuje tylko wybrane aktywacje zamiast wszystkich, ponownie je obliczajÄ…c podczas backward pass.

**WpÅ‚yw:**
- âœ… `true` â†’ Zmniejsza VRAM usage o **~40%**, training **~20% wolniejszy**
- âŒ `false` â†’ WiÄ™cej VRAM, szybszy training (moÅ¼e OOM na 3B modelu)

**Sugerowane wartoÅ›ci:**

| VRAM | Rekomendacja |
|------|--------------|
| < 16 GB | `true` (required) |
| 16-24 GB | `true` (optimal dla 3B) |
| > 40 GB | `false` (szybszy training) |

**Aktualna wartoÅ›Ä‡:** `true` âœ…

---

### `use_flash_attention_2`
**Typ:** `boolean`
**DomyÅ›lnie:** `true`

**Opis:**
UÅ¼ywa Flash Attention 2 (zoptymalizowana implementacja attention mechanism).

**WpÅ‚yw:**
- âœ… `true` â†’ **2-3x szybszy training**, mniej VRAM
- âš ï¸ Wymaga Ampere+ GPU (RTX 3000+, A100)
- âŒ Nie dziaÅ‚a na Windows (uÅ¼ywa eager attention fallback)

**Sugerowane wartoÅ›ci:**

| Platform | GPU | Rekomendacja |
|----------|-----|--------------|
| Linux | RTX 3090/4090, A5000+ | `true` |
| Windows | Any | `true` (auto fallback do eager) |
| Colab/RunPod | T4, A100 | `true` |

**Aktualna wartoÅ›Ä‡:** `true` âœ…

---

### `group_by_length`
**Typ:** `boolean`
**DomyÅ›lnie:** `true`

**Opis:**
Grupuje prÃ³bki o podobnej dÅ‚ugoÅ›ci w tym samym batchu, zmniejszajÄ…c padding.

**WpÅ‚yw:**
- âœ… `true` â†’ **~15% szybszy training**, mniej WASTED compute
- âŒ `false` â†’ Losowe dÅ‚ugoÅ›ci â†’ duÅ¼o paddingu â†’ wolniejszy

**Sugerowane wartoÅ›ci:**
- **Zawsze `true`** dla kodu (rÃ³Å¼ne dÅ‚ugoÅ›ci plikÃ³w)

**Aktualna wartoÅ›Ä‡:** `true` âœ…

---

## 2. Batching & Memory

### `per_device_train_batch_size`
**Typ:** `int`
**DomyÅ›lnie:** `4`

**Opis:**
Liczba prÃ³bek przetwarzanych jednoczeÅ›nie na GPU podczas treningu.

**WpÅ‚yw:**
- WiÄ™kszy batch â†’ stabilniejszy gradient, szybszy training, **wiÄ™cej VRAM**
- Mniejszy batch â†’ mniej VRAM, bardziej "noisy" gradient

**Sugerowane wartoÅ›ci:**

| VRAM | Batch Size | Gradient Accumulation | Efektywny Batch |
|------|------------|----------------------|-----------------|
| 8-12 GB | 1-2 | 16 | 16-32 |
| 16 GB | 2 | 8-16 | 16-32 |
| 24 GB | **4** | **8** | **32** âœ… |
| 40 GB | 8 | 4 | 32 |
| 80 GB | 16 | 2 | 32 |

**ReguÅ‚a:** Efektywny batch size = `per_device_train_batch_size Ã— gradient_accumulation_steps`
**Optimal:** 32-64 dla fine-tuningu maÅ‚ych modeli

**Aktualna wartoÅ›Ä‡:** `4` (efektywny: 32) âœ…

---

### `per_device_eval_batch_size`
**Typ:** `int`
**DomyÅ›lnie:** `4`

**Opis:**
Batch size podczas ewaluacji (moÅ¼e byÄ‡ wiÄ™kszy niÅ¼ train, bo nie trzeba gradientÃ³w).

**WpÅ‚yw:**
- WiÄ™kszy â†’ szybsza ewaluacja
- Brak limitu VRAM (forward pass only)

**Sugerowane wartoÅ›ci:**

| Train Batch | Eval Batch |
|-------------|------------|
| 1-2 | 4-8 |
| 4 | 8-16 |
| 8 | 16-32 |

**Aktualna wartoÅ›Ä‡:** `4` (moÅ¼na zwiÄ™kszyÄ‡ do 8-16) âš ï¸

---

### `gradient_accumulation_steps`
**Typ:** `int`
**DomyÅ›lnie:** `8`

**Opis:**
Liczba krokÃ³w forward/backward przed aktualizacjÄ… wag. Symuluje wiÄ™kszy batch size.

**WpÅ‚yw:**
- WiÄ™kszy â†’ efektywnie wiÄ™kszy batch, stabilniejszy gradient
- `effective_batch = per_device_train_batch_size Ã— gradient_accumulation_steps`

**Sugerowane wartoÅ›ci:**

| VRAM | Config | Efektywny Batch |
|------|--------|-----------------|
| 8-12 GB | batch=1, accum=32 | 32 |
| 16 GB | batch=2, accum=16 | 32 |
| 24 GB | **batch=4, accum=8** | **32** âœ… |
| 40+ GB | batch=8, accum=4 | 32 |

**Target:** Efektywny batch 32-64

**Aktualna wartoÅ›Ä‡:** `8` âœ…

---

## 3. QLoRA Configuration

### `use_qlora`
**Typ:** `boolean`
**DomyÅ›lnie:** `true`

**Opis:**
WÅ‚Ä…cza QLoRA (Quantized Low-Rank Adaptation) - efektywna metoda fine-tuningu.

**WpÅ‚yw:**
- âœ… `true` â†’ Model w 4-bit, tylko adaptery w FP16 â†’ **4x mniej VRAM**
- âŒ `false` â†’ Full fine-tuning â†’ wymaga 80+ GB VRAM dla 3B modelu

**Sugerowane wartoÅ›ci:**
- **Zawsze `true`** dla GPU <80GB

**Aktualna wartoÅ›Ä‡:** `true` âœ…

---

### `lora_r`
**Typ:** `int`
**DomyÅ›lnie:** `16`
**Zakres:** `4-64`

**Opis:**
Ranga macierzy LoRA. WyÅ¼szy rank â†’ wiÄ™cej parametrÃ³w do trenowania.

**WpÅ‚yw:**
- NiÅ¼szy (4-8) â†’ mniej parametrÃ³w, szybszy training, **moÅ¼e underfitowaÄ‡**
- WyÅ¼szy (32-64) â†’ wiÄ™cej parametrÃ³w, wolniejszy, **moÅ¼e overfitowaÄ‡**

**Sugerowane wartoÅ›ci:**

| Rozmiar Datasetu | Task Complexity | lora_r |
|------------------|-----------------|--------|
| < 1k samples | Simple | 8 |
| 1k - 10k | Moderate | **16** âœ… |
| 10k - 100k | Complex | 32 |
| > 100k | Very Complex | 64 |

**ReguÅ‚a:** `lora_alpha = 2 Ã— lora_r` (typowo)

**Aktualna wartoÅ›Ä‡:** `16` âœ…

---

### `lora_alpha`
**Typ:** `int`
**DomyÅ›lnie:** `32`

**Opis:**
Scaling factor dla LoRA adaptacji. Kontroluje siÅ‚Ä™ updatÃ³w.

**WpÅ‚yw:**
- WyÅ¼szy â†’ silniejsze updaty (szybsza konwergencja, ryzyko overfittingu)
- NiÅ¼szy â†’ delikatniejsze updaty (stabilniejszy training)

**Sugerowane wartoÅ›ci:**
- `lora_alpha = 2 Ã— lora_r` (standard)
- Dla overfittingu: `lora_alpha = lora_r` (sÅ‚absze updaty)

**Aktualna wartoÅ›Ä‡:** `32` (2Ã—16) âœ…

---

### `lora_dropout`
**Typ:** `float`
**DomyÅ›lnie:** `0.15`
**Zakres:** `0.0-0.5`

**Opis:**
Dropout w warstwach LoRA (regularizacja).

**WpÅ‚yw:**
- WyÅ¼szy (0.15-0.3) â†’ silniejsza regularizacja, **zapobiega overfittingowi**
- NiÅ¼szy (0.0-0.05) â†’ sÅ‚absza regularizacja, ryzyko overfittingu

**Sugerowane wartoÅ›ci:**

| Symptom | lora_dropout |
|---------|--------------|
| Overfitting (train>>test) | 0.2-0.3 |
| Balanced | **0.15** âœ… |
| Underfitting (train=test, obie niskie) | 0.05-0.1 |

**Aktualna wartoÅ›Ä‡:** `0.15` âœ…

---

### `target_modules`
**Typ:** `list[string]`
**DomyÅ›lnie:** `["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]`

**Opis:**
KtÃ³re warstwy modelu dostajÄ… LoRA adaptery.

**WpÅ‚yw:**
- WiÄ™cej moduÅ‚Ã³w â†’ wiÄ™cej parametrÃ³w, lepsza adaptacja, **wiÄ™cej VRAM**
- Mniej moduÅ‚Ã³w â†’ mniej parametrÃ³w, szybszy training

**Sugerowane wartoÅ›ci:**

| Preset | Modules | Use Case |
|--------|---------|----------|
| Minimal | `q_proj, v_proj` | Quick experiments |
| Standard | `q_proj, v_proj, k_proj, o_proj` | Balanced |
| **Full Attention** | **q, v, k, o, gate, up, down** | **Production** âœ… |

**Aktualna wartoÅ›Ä‡:** Full (7 moduÅ‚Ã³w) âœ…

---

## 4. Optimization & Regularization

### `learning_rate`
**Typ:** `float`
**DomyÅ›lnie:** `4e-5` (0.00004)
**Zakres:** `1e-6` - `5e-4`

**Opis:**
SzybkoÅ›Ä‡ uczenia siÄ™ modelu (rozmiar kroku w kierunku gradientu).

**WpÅ‚yw:**
- WyÅ¼szy (1e-4+) â†’ szybsza konwergencja, **niestabilny training**
- NiÅ¼szy (1e-5) â†’ stabilniejszy, **wolniejsza konwergencja**

**Sugerowane wartoÅ›ci:**

| Model Size | Task | Learning Rate |
|------------|------|---------------|
| 1B | Fine-tuning | 1e-4 |
| 3B | Fine-tuning | **4e-5** âœ… |
| 7B+ | Fine-tuning | 2e-5 |
| Any | From scratch | 1e-3 - 5e-3 |

**Symptomy:**
- Loss explodes â†’ **zmniejsz** (2e-5)
- Loss nie spada â†’ zwiÄ™ksz (1e-4)

**Aktualna wartoÅ›Ä‡:** `4e-5` âœ…

---

### `weight_decay`
**Typ:** `float`
**DomyÅ›lnie:** `0.15`
**Zakres:** `0.0-0.3`

**Opis:**
L2 regularizacja - karze duÅ¼e wagi (zapobiega overfittingowi).

**WpÅ‚yw:**
- WyÅ¼szy (0.15-0.3) â†’ silniejsza regularizacja, **zapobiega overfittingowi**
- NiÅ¼szy (0.01) â†’ sÅ‚absza regularizacja
- `0.0` â†’ brak regularizacji (tylko dla duÅ¼ych datasetÃ³w)

**Sugerowane wartoÅ›ci:**

| Dataset Size | Overfitting Risk | weight_decay |
|--------------|------------------|--------------|
| < 1k samples | High | 0.2-0.3 |
| 1k-10k | Moderate | **0.15** âœ… |
| 10k-100k | Low | 0.05-0.1 |
| > 100k | Very Low | 0.01 |

**Aktualna wartoÅ›Ä‡:** `0.15` (wysoka - walczy z overfittingiem) âœ…

---

### `label_smoothing_factor`
**Typ:** `float`
**DomyÅ›lnie:** `0.1`
**Zakres:** `0.0-0.3`

**Opis:**
ZmiÄ™kcza labele (zamiast [0,1] uÅ¼ywa [0.05, 0.95]). Model jest mniej "pewny".

**WpÅ‚yw:**
- âœ… `0.1-0.15` â†’ Model nie overfituje, **lepiej generalizuje**
- âœ… Pomaga z **Specificity: 0.00** (model przestaje klasyfikowaÄ‡ wszystko jako malicious)
- âŒ `0.0` â†’ Model pewny siebie (overfitting risk)

**Sugerowane wartoÅ›ci:**

| Problem | label_smoothing_factor |
|---------|------------------------|
| Model klasyfikuje wszystko jako jedna klasa | **0.1-0.15** âœ… |
| Overfitting (train>>test) | 0.15-0.2 |
| Underfitting | 0.0-0.05 |

**WAÅ»NE:** To jest **kluczowy parametr** dla Twojego problemu Specificity: 0.00!

**Aktualna wartoÅ›Ä‡:** `0.1` âœ…

---

### `optim`
**Typ:** `string`
**DomyÅ›lnie:** `"paged_adamw_8bit"`

**Opis:**
Optimizer uÅ¼ywany do aktualizacji wag.

**WpÅ‚yw:**
- `paged_adamw_8bit` â†’ **Najmniej VRAM**, niemal identyczny do AdamW
- `adamw_8bit` â†’ Nieco wiÄ™cej VRAM
- `adamw_torch` â†’ Full precision, duÅ¼o VRAM

**Sugerowane wartoÅ›ci:**

| VRAM | Optimizer |
|------|-----------|
| < 16 GB | `paged_adamw_8bit` |
| 16-24 GB | **`paged_adamw_8bit`** âœ… |
| > 40 GB | `adamw_torch` (nieznacznie lepsze wyniki) |

**Aktualna wartoÅ›Ä‡:** `paged_adamw_8bit` âœ…

---

## 5. Learning Rate Scheduling

### `lr_scheduler_type`
**Typ:** `string`
**DomyÅ›lnie:** `"cosine"`

**Opis:**
Jak learning rate zmienia siÄ™ podczas treningu.

**WpÅ‚yw:**
- `linear` â†’ LR liniowo spada (prosty, stabilny)
- `cosine` â†’ **Smooth spadek, warm restarts** (lepsze dla overfittingu)
- `constant` â†’ StaÅ‚y LR (tylko z warmup)

**Sugerowane wartoÅ›ci:**

| Training Length | Scheduler |
|----------------|-----------|
| 1-3 epochs | **`cosine`** âœ… |
| 5+ epochs | `cosine_with_restarts` |
| Quick experiments | `linear` |

**Aktualna wartoÅ›Ä‡:** `cosine` âœ…

---

### `warmup_steps`
**Typ:** `int`
**DomyÅ›lnie:** `100`
**Zakres:** `0-500`

**Opis:**
Liczba krokÃ³w z maÅ‚ym LR na poczÄ…tku (stopniowo roÅ›nie do `learning_rate`).

**WpÅ‚yw:**
- Zapobiega duÅ¼ym gradientom na poczÄ…tku (stabilizuje training)
- Za duÅ¼o â†’ training za wolny
- Za maÅ‚o â†’ niestabilny start

**Sugerowane wartoÅ›ci:**

| Total Steps | warmup_steps |
|-------------|--------------|
| < 500 | 50 |
| 500-2000 | **100** âœ… |
| 2000-5000 | 200-300 |
| > 5000 | 500 |

**ReguÅ‚a:** ~5-10% total steps

**Aktualna wartoÅ›Ä‡:** `100` âœ…

---

## 6. Evaluation & Monitoring

### `evaluation_strategy`
**Typ:** `string`
**DomyÅ›lnie:** `"steps"`

**Opis:**
Jak czÄ™sto uruchamiaÄ‡ ewaluacjÄ™ na test secie.

**WpÅ‚yw:**
- `steps` â†’ Co `eval_steps` krokÃ³w (najlepsze)
- `epoch` â†’ Po kaÅ¼dym epoce (OK dla wielu epochs)
- `no` â†’ Brak ewaluacji (tylko training loss)

**Sugerowane wartoÅ›ci:**
- **Zawsze `steps`** (pozwala na early stopping)

**Aktualna wartoÅ›Ä‡:** `steps` âœ…

---

### `eval_steps`
**Typ:** `int`
**DomyÅ›lnie:** `50`

**Opis:**
Co ile krokÃ³w uruchomiÄ‡ ewaluacjÄ™.

**WpÅ‚yw:**
- Mniejszy (25-50) â†’ czÄ™sta ewaluacja, **Å‚atwiej wykryÄ‡ overfitting**
- WiÄ™kszy (200+) â†’ rzadka ewaluacja, szybszy training

**Sugerowane wartoÅ›ci:**

| Total Steps | eval_steps |
|-------------|------------|
| < 500 | 25 |
| 500-2000 | **50** âœ… |
| 2000-5000 | 100 |
| > 5000 | 200 |

**ReguÅ‚a:** ~2-5% total steps

**Aktualna wartoÅ›Ä‡:** `50` âœ…

---

### `save_steps`
**Typ:** `int`
**DomyÅ›lnie:** `50`

**Opis:**
Co ile krokÃ³w zapisaÄ‡ checkpoint.

**WpÅ‚yw:**
- Mniejszy â†’ czÄ™ste zapisy, **wiÄ™cej dysku**
- WiÄ™kszy â†’ rzadkie zapisy, ryzyko utraty progressu

**Sugerowane wartoÅ›ci:**
- Powinien byÄ‡ **rÃ³wny `eval_steps`** (zapisuj po kaÅ¼dej ewaluacji)

**Aktualna wartoÅ›Ä‡:** `50` (= eval_steps) âœ…

---

### `load_best_model_at_end`
**Typ:** `boolean`
**DomyÅ›lnie:** `true`

**Opis:**
Po zakoÅ„czeniu trainingu wczytaj najlepszy checkpoint (wg `metric_for_best_model`).

**WpÅ‚yw:**
- âœ… `true` â†’ UÅ¼ywasz najlepszego modelu (nie ostatniego)
- Wymaga ewaluacji (`evaluation_strategy != "no"`)

**Sugerowane wartoÅ›ci:**
- **Zawsze `true`** (ostatni checkpoint moÅ¼e byÄ‡ overfitted)

**Aktualna wartoÅ›Ä‡:** `true` âœ…

---

### `metric_for_best_model`
**Typ:** `string`
**DomyÅ›lnie:** `"eval_loss"`

**Opis:**
Metryka uÅ¼ywana do wyboru najlepszego checkpointa.

**WpÅ‚yw:**
- `eval_loss` â†’ Wybiera checkpoint z najniÅ¼szym eval loss (typowy wybÃ³r)
- `eval_accuracy` â†’ Wybiera checkpoint z najwyÅ¼szÄ… accuracy

**Sugerowane wartoÅ›ci:**
- **`eval_loss`** dla wiÄ™kszoÅ›ci przypadkÃ³w âœ…

**Aktualna wartoÅ›Ä‡:** `eval_loss` âœ…

---

### `test_split_size`
**Typ:** `float`
**DomyÅ›lnie:** `0.2`
**Zakres:** `0.1-0.3`

**Opis:**
Frakcja danych uÅ¼ywana jako test set.

**WpÅ‚yw:**
- WiÄ™kszy (0.2-0.3) â†’ bardziej reliable eval, **mniej danych do treningu**
- Mniejszy (0.1) â†’ wiÄ™cej danych do treningu, mniej reliable eval

**Sugerowane wartoÅ›ci:**

| Dataset Size | test_split_size |
|--------------|-----------------|
| < 1k | 0.3 |
| 1k-10k | **0.2** âœ… |
| > 10k | 0.1 |

**Aktualna wartoÅ›Ä‡:** `0.2` âœ…

---

## 7. Early Stopping

### `early_stopping`
**Typ:** `boolean`
**DomyÅ›lnie:** `true`

**Opis:**
Zatrzymuje training gdy eval metric przestaje siÄ™ poprawiaÄ‡.

**WpÅ‚yw:**
- âœ… `true` â†’ OszczÄ™dza czas, **zapobiega overfittingowi**
- âŒ `false` â†’ Training do koÅ„ca epochs (moÅ¼e overfitowaÄ‡)

**Sugerowane wartoÅ›ci:**
- **Zawsze `true`** (zwÅ‚aszcza dla maÅ‚ych datasetÃ³w)

**Aktualna wartoÅ›Ä‡:** `true` âœ…

---

### `early_stopping_patience`
**Typ:** `int`
**DomyÅ›lnie:** `2`
**Zakres:** `1-5`

**Opis:**
Ile ewaluacji bez poprawy przed zatrzymaniem trainingu.

**WpÅ‚yw:**
- NiÅ¼szy (1-2) â†’ szybkie zatrzymanie (moÅ¼e przedwczeÅ›nie)
- WyÅ¼szy (5+) â†’ dÅ‚uÅ¼sze czekanie (moÅ¼e overfitowaÄ‡)

**Sugerowane wartoÅ›ci:**

| eval_steps | Patience | Stops After |
|------------|----------|-------------|
| 25 | 3 | 75 steps bez poprawy |
| 50 | **2** | **100 steps bez poprawy** âœ… |
| 100 | 2 | 200 steps bez poprawy |

**ReguÅ‚a:** Patience Ã— eval_steps = 100-200 steps

**Aktualna wartoÅ›Ä‡:** `2` âœ…

---

### `early_stopping_threshold`
**Typ:** `float`
**DomyÅ›lnie:** `0.001`

**Opis:**
Minimalna poprawa metryki uznawana za "improvement" (0.001 = 0.1%).

**WpÅ‚yw:**
- WiÄ™kszy (0.01) â†’ wymaga wyraÅºnej poprawy (wczeÅ›niejsze stopping)
- Mniejszy (0.0001) â†’ akceptuje maÅ‚e poprawy (dÅ‚uÅ¼szy training)

**Sugerowane wartoÅ›ci:**
- `0.001` (0.1% improvement) - standard âœ…
- `0.0` - kaÅ¼da poprawa siÄ™ liczy

**Aktualna wartoÅ›Ä‡:** `0.001` âœ…

---

## 8. Precision & Performance

### `bf16`
**Typ:** `boolean`
**DomyÅ›lnie:** `true`

**Opis:**
Brain Float 16 precision (FP16 z wiÄ™kszym zakresem).

**WpÅ‚yw:**
- âœ… `true` â†’ **2x szybszy training**, poÅ‚owa VRAM, identyczne wyniki
- Wymaga Ampere+ GPU (RTX 3000+, A100)

**Sugerowane wartoÅ›ci:**

| GPU | bf16 |
|-----|------|
| RTX 3090/4090, A5000+ | **`true`** âœ… |
| RTX 2080, V100 | `false` (uÅ¼yj fp16) |
| CPU | `false` |

**Aktualna wartoÅ›Ä‡:** `true` âœ…

---

### `tf32`
**Typ:** `boolean`
**DomyÅ›lnie:** `true`

**Opis:**
TensorFloat32 - uÅ¼ywa FP32 range z FP16 precision w operacjach tensorowych.

**WpÅ‚yw:**
- âœ… `true` â†’ **20% szybszy training** na Ampere GPU
- Tylko Ampere+ (RTX 3000+, A100)
- Nie wpÅ‚ywa na VRAM

**Sugerowane wartoÅ›ci:**

| GPU | tf32 |
|-----|------|
| RTX 3090/4090, A5000, A100 | **`true`** âœ… |
| Starsze GPU | `false` (brak wsparcia) |

**Aktualna wartoÅ›Ä‡:** `true` âœ…

---

## 9. Experiment Tracking

### `report_to`
**Typ:** `list[string]`
**DomyÅ›lnie:** `["wandb"]`

**Opis:**
Gdzie logowaÄ‡ metryki treningowe.

**WpÅ‚yw:**
- `wandb` â†’ Weights & Biases (cloud tracking)
- `tensorboard` â†’ Lokalne tensorboard
- `none` â†’ Brak trackingu

**Sugerowane wartoÅ›ci:**
- Development: `["wandb"]` âœ…
- Production: `["wandb", "tensorboard"]`
- Offline: `["tensorboard"]`

**Aktualna wartoÅ›Ä‡:** `["wandb"]` âœ…

---

### `run_name`
**Typ:** `string`
**DomyÅ›lnie:** `"scriptguard-balanced-v2"`

**Opis:**
Nazwa eksperymentu w Wandb.

**WpÅ‚yw:**
- Sensowna nazwa â†’ Å‚atwiej porÃ³wnaÄ‡ eksperymenty

**Sugerowane wartoÅ›ci:**
- Format: `{projekt}-{dataset}-{version}`
- PrzykÅ‚ad: `scriptguard-balanced-v3`, `scriptguard-dedup-85`

**Aktualna wartoÅ›Ä‡:** `scriptguard-balanced-v2` âœ…

---

## ğŸ¯ Quick Reference: Problemy i RozwiÄ…zania

### Problem: Overfitting (train 98%, test 85%)

**RozwiÄ…zanie:**
```yaml
weight_decay: 0.2              # byÅ‚o 0.15
lora_dropout: 0.2              # byÅ‚o 0.15
label_smoothing_factor: 0.15   # byÅ‚o 0.1
early_stopping_patience: 2     # juÅ¼ OK
```

---

### Problem: Underfitting (train i test oba ~70%)

**RozwiÄ…zanie:**
```yaml
learning_rate: 1e-4            # byÅ‚o 4e-5
lora_r: 32                     # byÅ‚o 16
weight_decay: 0.05             # byÅ‚o 0.15
num_epochs: 3                  # byÅ‚o 1
```

---

### Problem: Specificity: 0.00 (klasyfikuje wszystko jako malicious)

**RozwiÄ…zanie:** âœ… **JuÅ¼ zaimplementowane:**
```yaml
label_smoothing_factor: 0.1    # Model mniej pewny
augment_after_split: true      # Zapobiega data leakage
balance_method: "hybrid"       # Lepszy balans klas
dedup_threshold: 0.85          # WiÄ™cej diversity
```

---

### Problem: OOM (Out of Memory)

**RozwiÄ…zanie:**
```yaml
per_device_train_batch_size: 2  # byÅ‚o 4
gradient_accumulation_steps: 16 # byÅ‚o 8 (ten sam efektywny batch)
gradient_checkpointing: true    # juÅ¼ OK
```

---

### Problem: Training za wolny

**RozwiÄ…zanie:**
```yaml
group_by_length: true          # juÅ¼ OK
use_flash_attention_2: true    # juÅ¼ OK
tf32: true                     # juÅ¼ OK
per_device_train_batch_size: 8 # byÅ‚o 4 (jeÅ›li masz VRAM)
eval_steps: 100                # byÅ‚o 50 (rzadsza eval)
```

---

## ğŸ“Š Optimized Configurations

### Small Dataset (< 2k samples)
```yaml
learning_rate: 2e-5
weight_decay: 0.2
label_smoothing_factor: 0.15
lora_dropout: 0.2
early_stopping_patience: 2
num_epochs: 3
```

### Medium Dataset (2k-10k samples) - **YOUR CASE**
```yaml
learning_rate: 4e-5            # âœ… Current
weight_decay: 0.15             # âœ… Current
label_smoothing_factor: 0.1    # âœ… Current
lora_dropout: 0.15             # âœ… Current
early_stopping_patience: 2     # âœ… Current
num_epochs: 1                  # âœ… Current
```

### Large Dataset (> 10k samples)
```yaml
learning_rate: 4e-5
weight_decay: 0.05
label_smoothing_factor: 0.05
lora_dropout: 0.1
early_stopping_patience: 3
num_epochs: 1
```

---

## ğŸš€ Performance Optimization Checklist

- âœ… `gradient_checkpointing: true` - oszczÄ™dza VRAM
- âœ… `use_flash_attention_2: true` - 2-3x szybszy
- âœ… `tf32: true` - 20% szybszy (Ampere GPU)
- âœ… `bf16: true` - 2x szybszy
- âœ… `group_by_length: true` - 15% szybszy
- âœ… `per_device_train_batch_size: 4` - optimal dla 24GB
- âœ… `gradient_accumulation_steps: 8` - efektywny batch 32

**Wszystkie optymalizacje juÅ¼ wÅ‚Ä…czone!** ğŸ‰

---

## ğŸ“– Dalsze MateriaÅ‚y

- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [QLoRA Paper](https://arxiv.org/abs/2305.14314)
- [Hugging Face Training Guide](https://huggingface.co/docs/transformers/training)
- [Label Smoothing Explained](https://arxiv.org/abs/1906.02629)

---

**Ostatnia aktualizacja:** 2026-02-10
**Autor:** Claude (Anthropic) + ScriptGuard Team
