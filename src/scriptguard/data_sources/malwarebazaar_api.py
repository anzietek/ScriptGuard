"""
MalwareBazaar API Data Source
Fetches recent malware samples from MalwareBazaar (abuse.ch).
"""

from scriptguard.utils.logger import logger
from scriptguard.utils.archive_extractor import extract_scripts_from_archive
from scriptguard.utils.data_quality_filter import is_valid_source_code, quick_binary_check, log_rejection_stats
from scriptguard.utils.retry_utils import retry_with_backoff, RetryStats
import requests
import os
from typing import List, Dict, Optional
from datetime import datetime
import time

class MalwareBazaarDataSource:
    """MalwareBazaar API integration for fresh malware samples."""

    API_URL = "https://mb-api.abuse.ch/api/v1/"

    def __init__(self, api_key: Optional[str] = None, config: Optional[Dict] = None):
        """
        Initialize MalwareBazaar data source.

        Args:
            api_key: MalwareBazaar API key (optional, but recommended for higher limits)
            config: Configuration dictionary with retry/timeout settings
        """
        self.api_key = api_key or os.getenv("MALWAREBAZAAR_API_KEY", "")
        self.config = config or {}

        # Read configuration with fallback defaults
        source_config = self.config.get("data_sources", {}).get("malwarebazaar", {})
        self.timeout = source_config.get("timeout", 60)
        self.max_retries = source_config.get("max_retries", 3)
        self.retry_backoff_factor = source_config.get("retry_backoff_factor", 2.0)

        # Initialize retry statistics tracking
        self.retry_stats = RetryStats()

        if self.api_key:
            logger.info("MalwareBazaar API key configured")
        else:
            logger.warning("No MalwareBazaar API key - requests may be rate limited or fail")

    def _make_request(self, endpoint: str, data: Dict) -> Optional[Dict]:
        """
        Make POST request to MalwareBazaar API with retry logic.

        Args:
            endpoint: API endpoint
            data: Request payload

        Returns:
            JSON response or None on error
        """
        headers = {"Accept": "application/json"}

        if self.api_key:
            headers["Auth-Key"] = self.api_key

        retry_count = 0

        @retry_with_backoff(
            max_retries=self.max_retries,
            backoff_factor=self.retry_backoff_factor,
            initial_delay=1.0,
            exceptions=(requests.exceptions.Timeout, requests.exceptions.RequestException),
            on_retry=lambda e, attempt: setattr(self, '_last_retry_count', attempt)
        )
        def _do_request():
            response = requests.post(
                f"{self.API_URL}{endpoint}",
                data=data,
                headers=headers,
                timeout=self.timeout
            )

            if response.status_code == 200:
                return response.json()
            elif response.status_code == 401:
                logger.error("MalwareBazaar API authentication failed - check API key validity")
                raise Exception("Authentication failed")  # Don't retry auth failures
            else:
                logger.warning(f"MalwareBazaar API returned status {response.status_code}")
                raise Exception(f"HTTP {response.status_code}")  # Retry other errors

        try:
            self._last_retry_count = 0
            result = _do_request()
            self.retry_stats.record_attempt("api_request", True, self._last_retry_count)
            return result
        except Exception as e:
            retry_count = getattr(self, '_last_retry_count', self.max_retries)
            self.retry_stats.record_attempt("api_request", False, retry_count)
            logger.error(f"MalwareBazaar request failed after retries: {e}")
            return None

    def get_recent_samples(self, limit: int = 100) -> List[Dict]:
        """
        Get recent malware samples.

        Args:
            limit: Maximum number of samples (max 1000, but API doesn't support limit parameter)

        Returns:
            List of sample metadata
        """
        logger.info(f"Fetching recent samples from MalwareBazaar (returns max 100)")

        data = {
            "query": "get_recent",
            "selector": "time"  # API requires 'time' as selector
        }

        response = self._make_request("", data)

        if not response or response.get("query_status") != "ok":
            logger.error("Failed to fetch recent samples")
            return []

        samples = response.get("data", [])
        # Limit to requested number since API doesn't support limit param
        samples = samples[:limit] if samples else []
        logger.info(f"Retrieved {len(samples)} samples")
        return samples

    def search_by_tag(self, tag: str, limit: int = 100) -> List[Dict]:
        """
        Search samples by tag.

        Args:
            tag: Tag to search (e.g., "python", "script", "ransomware")
            limit: Maximum number of results

        Returns:
            List of sample metadata
        """
        logger.info(f"Searching MalwareBazaar for tag: {tag}")

        data = {
            "query": "get_taginfo",
            "tag": tag,
            "limit": limit
        }

        response = self._make_request("", data)

        if not response or response.get("query_status") != "ok":
            logger.warning(f"No results for tag: {tag}")
            return []

        samples = response.get("data", [])
        logger.info(f"Found {len(samples)} samples for tag '{tag}'")
        return samples

    def download_sample(self, sha256_hash: str) -> Optional[bytes]:
        """
        Download malware sample by SHA256 hash with retry logic.

        Args:
            sha256_hash: SHA256 hash of the sample

        Returns:
            Sample content as bytes or None
        """
        data = {
            "query": "get_file",
            "sha256_hash": sha256_hash
        }

        headers = {"Accept": "application/zip"}
        if self.api_key:
            headers["Auth-Key"] = self.api_key

        @retry_with_backoff(
            max_retries=self.max_retries,
            backoff_factor=self.retry_backoff_factor,
            initial_delay=1.0,
            exceptions=(requests.exceptions.Timeout, requests.exceptions.RequestException),
            on_retry=lambda e, attempt: setattr(self, '_last_download_retry', attempt)
        )
        def _do_download():
            response = requests.post(
                f"{self.API_URL}",
                data=data,
                headers=headers,
                timeout=self.timeout
            )

            if response.status_code == 200 and len(response.content) > 0:
                try:
                    import pyzipper
                    HAS_PYZIPPER = True
                except ImportError:
                    import zipfile
                    pyzipper = None
                    HAS_PYZIPPER = False

                import io

                try:
                    if HAS_PYZIPPER:
                        with pyzipper.AESZipFile(io.BytesIO(response.content)) as zf:
                            for filename in zf.namelist():
                                try:
                                    return zf.read(filename, pwd=b"infected")
                                except:
                                    try:
                                        return zf.read(filename)
                                    except:
                                        continue
                            logger.warning(f"No files extracted from ZIP for {sha256_hash}")
                            raise Exception("No files in ZIP")
                    else:
                        import zipfile as zf_lib
                        with zf_lib.ZipFile(io.BytesIO(response.content)) as zf:
                            for filename in zf.namelist():
                                try:
                                    return zf.read(filename, pwd=b"infected")
                                except NotImplementedError:
                                    logger.warning(f"Unsupported compression for {filename}, need pyzipper")
                                    continue
                                except RuntimeError:
                                    try:
                                        return zf.read(filename)
                                    except:
                                        continue
                            logger.warning(f"No files extracted from ZIP for {sha256_hash}")
                            raise Exception("No files in ZIP")
                except Exception as e:
                    logger.error(f"ZIP extraction error for {sha256_hash}: {e}")
                    raise

            elif response.status_code == 404:
                logger.warning(f"Sample {sha256_hash} not available for download")
                raise Exception("Sample not found (404)")  # Don't retry 404
            else:
                raise Exception(f"HTTP {response.status_code}")

        try:
            self._last_download_retry = 0
            result = _do_download()
            retry_count = getattr(self, '_last_download_retry', 0)
            self.retry_stats.record_attempt("download_sample", True, retry_count)
            return result
        except Exception as e:
            retry_count = getattr(self, '_last_download_retry', self.max_retries)
            self.retry_stats.record_attempt("download_sample", False, retry_count)
            logger.error(f"Failed to download sample {sha256_hash} after retries: {e}")
            return None

    def get_sample_info(self, sha256_hash: str) -> Optional[Dict]:
        """
        Get detailed information about a sample.

        Args:
            sha256_hash: SHA256 hash of the sample

        Returns:
            Sample metadata or None
        """
        data = {
            "query": "get_info",
            "hash": sha256_hash
        }

        response = self._make_request("", data)

        if not response or response.get("query_status") != "ok":
            return None

        return response.get("data", [{}])[0] if response.get("data") else None

    def fetch_malicious_samples(
        self,
        tags: Optional[List[str]] = None,
        max_samples: int = 100
    ) -> List[Dict]:
        """
        Fetch malicious script samples from MalwareBazaar.

        Args:
            tags: List of tags to search (e.g., ["python", "script"])
            max_samples: Maximum total samples to fetch

        Returns:
            List of samples with content and metadata
        """
        if tags is None:
            tags = [
                "python",
                "script",
                "ransomware",
                "backdoor",
                "stealer",
                "downloader"
            ]

        all_samples = []
        samples_per_tag = max(1, max_samples // len(tags))
        rejection_counts = {}  # Track rejection reasons for stats
        total_fetched = 0

        for tag in tags:
            logger.info(f"Fetching samples for tag: {tag}")
            samples_metadata = self.search_by_tag(tag, limit=samples_per_tag)

            for sample_meta in samples_metadata:
                file_name = sample_meta.get("file_name", "").lower()
                file_type = sample_meta.get("file_type", "").lower()
                sha256 = sample_meta.get("sha256_hash")

                if not sha256:
                    continue

                content_bytes = self.download_sample(sha256)
                if not content_bytes:
                    logger.warning(f"Could not download sample: {sha256}")
                    continue

                # Early binary check BEFORE extraction (fast!)
                if quick_binary_check(content_bytes):
                    logger.debug(f"Rejected binary file before extraction: {sha256}")
                    rejection_counts["binary_before_extraction"] = rejection_counts.get("binary_before_extraction", 0) + 1
                    continue

                scripts = extract_scripts_from_archive(content_bytes, file_name)

                for script_name, script_content in scripts:
                    total_fetched += 1

                    # Early quality filter - reject binary/garbage before pipeline
                    file_ext = os.path.splitext(script_name)[1] if script_name else None
                    is_valid, rejection_reason = is_valid_source_code(script_content, file_ext)

                    if not is_valid:
                        logger.debug(f"Rejected {script_name}: {rejection_reason}")
                        rejection_counts[rejection_reason] = rejection_counts.get(rejection_reason, 0) + 1
                        continue

                    all_samples.append({
                        "content": script_content,
                        "label": "malicious",
                        "source": "malwarebazaar",
                        "url": f"https://bazaar.abuse.ch/sample/{sha256}/",
                        "metadata": {
                            "sha256": sha256,
                            "file_name": script_name,
                            "original_file": sample_meta.get("file_name"),
                            "file_type": file_type,
                            "signature": sample_meta.get("signature"),
                            "tags": sample_meta.get("tags", []),
                            "first_seen": sample_meta.get("first_seen"),
                            "fetched_at": datetime.now().isoformat()
                        }
                    })

                    if len(all_samples) >= max_samples:
                        break

                time.sleep(1)

                if len(all_samples) >= max_samples:
                    break

            if len(all_samples) >= max_samples:
                break

            # Rate limiting between tags
            time.sleep(2)

        # Log rejection statistics
        log_rejection_stats(total_fetched, rejection_counts)

        logger.info(f"âœ“ Fetched {len(all_samples)} clean malicious samples from MalwareBazaar (filtered {total_fetched - len(all_samples)} low-quality)")
        return all_samples
